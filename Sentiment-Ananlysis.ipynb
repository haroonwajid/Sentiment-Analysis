{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d99467b",
   "metadata": {},
   "source": [
    "# Haroon Wajid\n",
    "# 21i-1763\n",
    "# DS-C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfea548",
   "metadata": {},
   "source": [
    "# 1. Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a8aee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reviewerID\": \"A30TL5EWN6DFXT\", \"asin\": \"120401325X\", \"reviewerName\": \"christina\", \"helpful\": [0, 0], \"reviewText\": \"They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\", \"overall\": 4.0, \"summary\": \"Looks Good\", \"unixReviewTime\": 1400630400, \"reviewTime\": \"05 21, 2014\"}\n",
      "\n",
      "{\"reviewerID\": \"ASY55RVNIL0UD\", \"asin\": \"120401325X\", \"reviewerName\": \"emily l.\", \"helpful\": [0, 0], \"reviewText\": \"These stickers work like the review says they do. They stick on great and they stay on the phone. They are super stylish and I can share them with my sister. :)\", \"overall\": 5.0, \"summary\": \"Really great product.\", \"unixReviewTime\": 1389657600, \"reviewTime\": \"01 14, 2014\"}\n",
      "\n",
      "{\"reviewerID\": \"A2TMXE2AFO7ONB\", \"asin\": \"120401325X\", \"reviewerName\": \"Erica\", \"helpful\": [0, 0], \"reviewText\": \"These are awesome and make my phone look so stylish! I have only used one so far and have had it on for almost a year! CAN YOU BELIEVE THAT! ONE YEAR!! Great quality!\", \"overall\": 5.0, \"summary\": \"LOVE LOVE LOVE\", \"unixReviewTime\": 1403740800, \"reviewTime\": \"06 26, 2014\"}\n",
      "\n",
      "{\"reviewerID\": \"AWJ0WZQYMYFQ4\", \"asin\": \"120401325X\", \"reviewerName\": \"JM\", \"helpful\": [4, 4], \"reviewText\": \"Item arrived in great time and was in perfect condition. However, I ordered these buttons because they were a great deal and included a FREE screen protector. I never received one. Though its not a big deal, it would've been nice to get it since they claim it comes with one.\", \"overall\": 4.0, \"summary\": \"Cute!\", \"unixReviewTime\": 1382313600, \"reviewTime\": \"10 21, 2013\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# Read JSON data from a file line by line\n",
    "with open(\"inputcell.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            # Parse JSON data from each line\n",
    "            json_data = json.loads(line)\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "# Open the JSON file\n",
    "with open(\"inputcell.json\", \"r\") as file:\n",
    "    # Read and print the first 10 lines\n",
    "    for i, line in enumerate(file):\n",
    "        print(line)\n",
    "        if i == 3:  # Stop after printing 3 lines\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a2bbf",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ccacac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of preprocessed reviews: 194439\n",
      "Sample preprocessed review: ('10pm case protects 7am lasts end battery usually start day buttons phone 55 full around glad good house leave return charges im build solid access', 5.0)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def load_json_iteratively(file_path):\n",
    "    \"\"\"Loads JSON data line by line for memory efficiency.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            yield json.loads(line)\n",
    "\n",
    "def preprocess_text_inplace(text):\n",
    "    \"\"\"Preprocesses text in-place for potential performance gains.\"\"\"\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stop_words_set(text, stop_words):\n",
    "    \"\"\"Removes stop words using a set for efficient membership checks.\"\"\"\n",
    "    words = text.split()\n",
    "    filtered_words = {word for word in words if word not in stop_words}\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Load stop words from a local file (replace with your file path)\n",
    "with open('custom_stopwords.txt', 'r') as file:\n",
    "    stop_words = set(file.read().splitlines())\n",
    "\n",
    "# Preprocess data using a generator for memory optimization\n",
    "def preprocess_data_generator(file_path):\n",
    "    for review in load_json_iteratively(file_path):\n",
    "        text = preprocess_text_inplace(review['reviewText'])\n",
    "        text = remove_stop_words_set(text, stop_words)\n",
    "        yield text, review['overall']\n",
    "\n",
    "# Step 1: Data Loading & Preprocessing\n",
    "preprocessed_data = list(preprocess_data_generator('inputcell.json'))\n",
    "\n",
    "# Explore preprocessed dataset\n",
    "print(\"Number of total preprocessed reviews:\", len(preprocessed_data))\n",
    "print(\"Sample preprocessed review:\", preprocessed_data[8])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3a8ba",
   "metadata": {},
   "source": [
    "# 2. Thematic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba107b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 most common positive words:\n",
      "the: 731041\n",
      "and: 388935\n",
      "i: 384546\n",
      "it: 357198\n",
      "a: 355952\n",
      "\n",
      "Top 5 most common negative words:\n",
      "the: 119284\n",
      "i: 64810\n",
      "it: 62416\n",
      "to: 54703\n",
      "and: 52320\n"
     ]
    }
   ],
   "source": [
    "def separate_reviews(preprocessed_data, rating_threshold=4):\n",
    "    \"\"\"Separates reviews into positive and negative based on a rating threshold.\"\"\"\n",
    "    positive_reviews = []\n",
    "    negative_reviews = []\n",
    "    for review, rating in preprocessed_data:\n",
    "        if rating >= rating_threshold:\n",
    "            positive_reviews.append(review)\n",
    "        elif rating <= (rating_threshold - 2):  # Adjust threshold for negative reviews\n",
    "            negative_reviews.append(review)\n",
    "    return positive_reviews, negative_reviews\n",
    "\n",
    "def count_words(words):\n",
    "    \"\"\"Counts word occurrences using a dictionary.\"\"\"\n",
    "    word_counts = {}\n",
    "    for word in words:\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    return word_counts\n",
    "\n",
    "def sort_and_print_top_words(word_counts, label, num_words=5):\n",
    "    \"\"\"Sorts and prints the top words for a given label.\"\"\"\n",
    "    sorted_words = sorted(word_counts.items(), key=lambda item: item[1], reverse=True)[:num_words]\n",
    "    print(f\"\\nTop {num_words} most common {label} words:\")\n",
    "    for word, count in sorted_words:\n",
    "        print(f\"{word}: {count}\")\n",
    "\n",
    "# Load and preprocess data\n",
    "file_path = 'inputcell.json'\n",
    "json_data = json.loads(line)\n",
    "preprocessed_data = [(preprocess_text(review['reviewText']), review['overall']) for review in data]\n",
    "\n",
    "# Separate reviews and count words\n",
    "positive_reviews, negative_reviews = separate_reviews(preprocessed_data)\n",
    "positive_word_counts = count_words(' '.join(positive_reviews).split())\n",
    "negative_word_counts = count_words(' '.join(negative_reviews).split())\n",
    "\n",
    "# Print results\n",
    "sort_and_print_top_words(positive_word_counts, \"positive\")\n",
    "sort_and_print_top_words(negative_word_counts, \"negative\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c184b32",
   "metadata": {},
   "source": [
    "# 3. Semantic Analysis and storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff175b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of example text: Negative\n",
      "Some of the sentiment Results are:\n",
      "Review: item arrived in great time and was in perfect cond... | Sentiment: Positive\n",
      "Review: awesome stays on and looks great can be used on mu... | Sentiment: Positive\n",
      "Review: these make using the home button easy my daughter ... | Sentiment: Neutral\n",
      "Review: came just as described it doesnt come unstuck and ... | Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "def split_and_lowercase(text):\n",
    "    \"\"\"Splits text into words and converts them to lowercase.\"\"\"\n",
    "    return re.sub(r\"[^\\w]\", \" \", text.lower()).split()\n",
    "\n",
    "def count_word_occurrences(words, word_sets):\n",
    "    \"\"\"Counts occurrences of words in each given word set within a list of words.\"\"\"\n",
    "    counts = {tuple(word_set): 0 for word_set in word_sets}\n",
    "    for word in words:\n",
    "        for word_set in word_sets:\n",
    "            if word in word_set:\n",
    "                counts[tuple(word_set)] += 1\n",
    "    return counts\n",
    "\n",
    "def analyze_sentiment(review_text, positive_words, negative_words, neutral_words=None):\n",
    "    \"\"\"Analyzes sentiment of a review text based on weighted word lists.\"\"\"\n",
    "    words = split_and_lowercase(review_text)\n",
    "    word_counts = count_word_occurrences(words, [positive_words, negative_words] + [neutral_words] if neutral_words else [positive_words, negative_words])\n",
    "    sentiment_score = 0\n",
    "    \n",
    "    for word_set, weight in [(positive_words, 0.65), (negative_words, -0.2)]:\n",
    "        sentiment_score += word_counts.get(tuple(word_set), 0) * weight\n",
    "    \n",
    "    if neutral_words:\n",
    "        sentiment_score += word_counts.get(tuple(neutral_words), 0) * 0.1  # Adjust neutral weight\n",
    "\n",
    "    # Define thresholds for classification based on your data and desired accuracy\n",
    "    if sentiment_score > 0.2:\n",
    "        return \"Positive\"\n",
    "    elif sentiment_score < -0.2:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "\n",
    "# Define word lists with weights and (optional) neutral words\n",
    "positive_words = {\"good\", \"excellent\", \"great\", \"wonderful\", \"awesome\",\n",
    "    \"fantastic\", \"amazing\", \"superb\", \"terrific\", \"outstanding\",\n",
    "    \"marvelous\", \"splendid\", \"brilliant\", \"phenomenal\", \"remarkable\",\n",
    "    \"stellar\", \"spectacular\", \"fabulous\", \"incredible\", \"glorious\",\n",
    "    \"majestic\", \"unbelievable\", \"top-notch\", \"first-rate\", \"praiseworthy\"}  \n",
    "\n",
    "negative_words = {\"bad\", \"terrible\", \"horrible\",\"disappointing\", \"awful\",\n",
    "    \"horrible\", \"subpar\", \"mediocre\", \"inferior\", \"low-quality\",\n",
    "    \"unsatisfactory\", \"unreliable\", \"defective\", \"faulty\", \"displeasing\",\n",
    "    \"disgusting\", \"unpleasant\", \"worse\", \"crap\", \"junk\",\n",
    "    \"garbage\", \"useless\", \"flawed\", \"cheap\", \"shoddy\"}\n",
    "\n",
    "neutral_words = {\"the\", \"is\", \"it\", \"this\", \"that\", \"and\", \n",
    "                 \"or\", \"but\", \"with\", \"for\", \"as\", \"on\", \"at\",\n",
    "                 \"in\", \"of\", \"to\", \"from\"}  \n",
    "\n",
    "\n",
    "# Example review text\n",
    "review_text = \"product was  terrible and bad and horrible.\"\n",
    "\n",
    "# Analyze sentiment\n",
    "sentiment = analyze_sentiment(review_text, positive_words, negative_words, neutral_words)\n",
    "print(\"Sentiment of example text:\", sentiment)\n",
    "#---------------------------------------------------------------------------\n",
    "# Categorize reviews and print results\n",
    "sentiment_results = categorize_reviews(preprocessed_data, positive_words, negative_words)\n",
    "\n",
    "print(\"Some of the sentiment Results are:\")\n",
    "for i in range(3, 7):\n",
    "    review, sentiment = sentiment_results[i]\n",
    "    print(f\"Review: {review}... | Sentiment: {sentiment}\")\n",
    "\n",
    "# Write results to a file\n",
    "with open(\"sentiment_results.txt\", \"w\") as file:\n",
    "    for index, (review, sentiment) in enumerate(sentiment_results):\n",
    "        if 3 <= index < 100:\n",
    "            file.write(f\"Review: {review} | Sentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ee495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe3a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7093f5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136a108c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
